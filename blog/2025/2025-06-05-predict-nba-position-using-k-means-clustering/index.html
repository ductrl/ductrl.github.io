<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>In this project, we will use K-means clustering to <em>sort of</em> predict an NBA player’s position based on their height and weight. For more detailed descriptions and codes, check out the <a href="https://colab.research.google.com/drive/1CCqjMUi7J4fvKlMkVkInOEJ0ZqlXIgVt?usp=sharing" rel="external nofollow noopener" target="_blank">Google Colab notebook</a> of this project to learn more.</p> <p><br></p> <h1 id="1-project-setup">1. Project Setup</h1> <p>Based on NBA players’ heights and weights, we will use <strong>K-means clustering</strong> to determine whether players can be grouped into position-based clusters. (k = 3 for guard, forward, center; k = 5 for PG, SG, SF, PF, C).</p> <p><br></p> <h1 id="2-data-preparation">2. Data Preparation</h1> <p>For this project, we will use the <a href="https://www.kaggle.com/datasets/damirdizdarevic/nba-dataset-eda-and-ml-compatible/data" rel="external nofollow noopener" target="_blank">NBA Player Data (1996-2024)</a> dataset from Kaggle. This dataset provides the height and weight of individual NBA players (as well as other stats, which we will not use in this project.). As there is no label, an unsupervised learning algorithm such as K-means clustering can come in handy.</p> <p><br></p> <h3 id="data-cleaning">Data cleaning</h3> <p>Firstly, it might be useful to visualize the raw data as a scatterplot. We will do this again after our model has clustered the data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">player_height</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">player_weight</span><span class="sh">'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Height (cm)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Weight (kg)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <figure> <img src="https://i.postimg.cc/kXKdsQQT/image.png" alt="my alt text"> <figcaption style="text-align: center; font-size: 0.9em; color: #888; margin-top: 0.5em;"> The generated scatterplot. </figcaption> </figure> <p>From this plot, we can see that the clusters aren’t visually obvious, and there are possible outliers (players below 170 cm).</p> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>As I am writing this blog post, I realized that I did not address the outliers at all. One way you can deal with this is simply by removing them (some common thresholds are samples that are at least 3 standard deviations from the means or the IQR rule). Another way is to treat them like missing data and impute them.</p> </blockquote> <p>This dataset does not have any empty values, so this is not an issue. However, since height and weight have different scales, we want to rescale them so that one feature doesn’t weigh (no pun intended) more than the other. In this case, I prefer standardization to normalization because K-means clustering uses Euclidean distance, which is sensitive to variance, and standardization preserves the variance of the data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <p>Now, using <code class="language-plaintext highlighter-rouge">scaled_df.describe()</code>, we should see that the scaled data has a mean of 0 and a standard deviation of 1.</p> <p><br></p> <h1 id="3-modeling">3. Modeling</h1> <p>Implementing a K-means clustering model is quite straightforward. Here, we will use <code class="language-plaintext highlighter-rouge">KMeans</code> from <code class="language-plaintext highlighter-rouge">sklearn.cluster</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">scaled_df</span><span class="p">)</span>
</code></pre></div></div> <p>Now we can visualize the clusters labeled by our model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">player_height</span><span class="sh">'</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">player_weight</span><span class="sh">'</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Height (cm)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Weight (kg)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <figure> <img src="https://i.postimg.cc/Y04tMTm7/image.png" alt="my alt text"> <figcaption style="text-align: center; font-size: 0.9em; color: #888; margin-top: 0.5em;"> The result scatterplot. </figcaption> </figure> <p>Based on typical height and weight ranges, we can infer that cluster 0 likely represents guards, 1 represents forwards, and 2 represents centers. You can try and see if these results would correctly categorize your favorite NBA player’s position or not! Just like with the linear regression model, this model also does not do well with Giannis. Maybe he’s just a one-of-a-kind player :)</p> <p><br></p> <h1 id="4-final-words">4. Final Words</h1> <p>While you’re here, this is part 2 of a machine learning project series where I apply every machine learning algorithm I learned to an NBA-related project. If you want to check out more similar projects, look around my blog and stay tuned for more!</p> </body></html>